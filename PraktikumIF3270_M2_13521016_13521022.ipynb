{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"b4997e854e724ab98753a20e37af32be","deepnote_cell_type":"markdown"},"source":"# Praktikum IF3270 2023/2024\n\nTujuan praktikum IF3270 Pembelajaran Mesin:\n1.   Peserta memahami rangkaian proses analitik data menggunakan pendekatan pembelajaran mesin. \n2.   Peserta memahami bahwa proses pengembangan model pembelajaran mesin juga ditentukan dari kualitas data, penanganan data, dan penentuan algoritma serta hyperparameter-nya; tidak cukup hanya dengan memastikan implementasi algoritma berjalan tanpa kesalahan.\n3.   Peserta mampu menginterpretasikan hasil dari evaluasi model dalam proses analitik menggunakan pendekatan pembelajaran mesin.\n\nPraktikum dilaksanakan secara berkelompok. Setiap kelompok terdiri atas 2 mahasiswa. Perhatikan bahwa terdapat berkas yang harus dikumpulkan saat keberjalanan praktikum untuk bagian A (25 April 2024, pukul 12.00 WIB) dan berkas yang dikumpulkan setelah waktu praktikum selesai untuk bagian B (25 April 2024, pukul 21.00 WIB).","block_group":"6b38e9981d2941e8a3f844e7c8882778"},{"cell_type":"markdown","metadata":{"cell_id":"168a16b5e56744f5b0144eec37c50053","deepnote_cell_type":"markdown"},"source":"Disediakan data yang sudah dibagi menjadi data latih (`df_train`), data validasi (`df_val`), dan data uji (`df_test`).\n\n**Bagian 1**: (batas waktu: 25 April 2024, 12.00 WIB)\n\n1. Buatlah _baseline_ dengan menggunakan model _logistic regression_.\n2. Lakukan analisis data terkait hal berikut:\n    - _duplicate value_,\n    - _missing value_,\n    - _outlier_,\n    - _balance of data_.\n3. Jelaskan rencana penanganan yang ada pada poin 2.\n4. Jelaskan teknik _encoding_ yang digunakan terhadap data yang disediakan apabila dilakukan, disertai dengan alasan.\n5. Buatlah desain eksperimen dengan menentukan hal berikut:\n    - tujuan eksperimen,\n    - variabel dependen dan independen,\n    - strategi eksperimen,\n    - skema validasi.\n    \n**Bagian 2**: (batas waktu: 25 April 2024, 21.00 WIB)\n\n6. Implementasikan strategi eksperimen dan skema validasi yang telah ditentukan pada poin 5.\n7. Berdasarkan hasil prediksi yang dihasilkan, buatlah kesimpulan analisis **hasil diabetes**.\n\n---\nCatatan:\n- Jika terdapat perubahan jawaban pada poin 1—5 (contoh: perbedaan penanganan _outlier_), jelaskan pada laporan mengenai jawaban sebelum, jawaban sesudah, dan alasan pengubahan jawaban.\n- Eksperimen dapat berupa penggantian model klasifikasi, pengaturan hyperparameter, model stacking, grid search, oversampling, undersampling, dan lain sebagainya. Semakin variatif eksperimen yang dilakukan, semakin baik.","block_group":"286b2a9f7cb74230960ddb2c74df4046"},{"cell_type":"markdown","metadata":{"cell_id":"0b8f4c3575b840a98abadeaac0cc3f60","deepnote_cell_type":"markdown"},"source":"## Dataset\n`diabetes.csv` merupakan dataset yang telah dimodifikasi dari [Diabetes Health Indicators Dataset](https://www.kaggle.com/datasets/alexteboul/diabetes-health-indicators-dataset/) sebagai kumpulan indikator individu yang diperoleh dari survei untuk kasus diabetes. Dataset ini berguna untuk melakukan prediksi diabetes sehingga suatu individu dapat diketahui memiliki risiko tinggi diabetes atau tidak. Hal ini diperoleh dari fitur-fitur yang dapat dianalisis lebih lanjut sebelum mencapai kesimpulan.\n\nBerikut adalah deskripsi singkat setiap kolom:\n\n1. **HighBP**: Memiliki tekanan darah tinggi (BP: Blood Pressure) atau tidak\n2. **HighChol**: Kolesterol tinggi atau tidak\n3. **BMI**: Besaran Body Mass Index\n4. **Smoker**: Perokok atau bukan perokok\n5. **Stroke**: Pernah mengalami struk atau tidak\n6. **HeartDiseaseorAttack**: Memiliki riwayat penyakit antara jantung koroner dan serangan jantung atau tidak sama sekali\n7. **PhysActivity**: Aktif secara fisik dalam 30 hari terakhir atau tidak\n8. **Fruits**: Mengonsumsi buah setiap hari atau tidak \n9. **Veggies**: Mengonsumsi sayur setiap hari atau tidak\n10. **HvyAlcoholConsump**: Peminum berat alkohol atau bukan \n11. **AnyHealthcare**: Memiliki perlindungan kesehatan atau tidak, contohnya memiliki asuransi kesehatan\n12. **GenHtlth**: Evaluasi mandiri terhadap kesehatan, skala 1-5 (1: Sangat baik, 2: Cukup Baik, 3: Baik, 4: Biasa saja, 5: Buruk)\n13. **MentHlth**: Jumlah hari keadaan mental buruk dalam 30 hari terakhir (skala 0-30 hari)  \n14. **PhysHlth**: Jumlah hari keadaan fisik buruk dalam 30 hari terakhir (skala 0-30 hari)\n15. **DiffWalk**: Memiliki kesulitan berjalan atau menaiki tangga\n16. **Sex**: (M) Male atau (F) Female\n17. **Age**: 13 kategori umur (1: 18-24 tahun, 9: 60-64 tahun, 13: 80 tahun ke atas)\n18. **Education**: Level edukasi skala 1-6 (1: Tidak pernah sekolah atau hanya TK, 2: SD, dst)\n19. **Income**: Skala pendapatan 1-8\n20. **Diabetes**: Apakah mengalami diabetes atau tidak (Kolom target)","block_group":"097678d279d34875a98ecc744bce186c"},{"cell_type":"markdown","metadata":{"cell_id":"6c3590b03806490d9dd6382db219beec","deepnote_cell_type":"markdown"},"source":"_Deliverable_ yang akan dihasilkan adalah sebagai berikut:\n1. berkas _notebook_ dengan format nama `PraktikumIF3270_M1_NIM1_NIM2.ipynb` untuk Bagian 1;\n2. berkas _notebook_ dengan format nama `PraktikumIF3270_M2_NIM1_NIM2.ipynb` untuk Bagian 1 + Bagian 2; serta\n3. berkas laporan dengan format nama `PraktikumIF3270_NIM1_NIM2.pdf` yang mencakup hal berikut:\n    - hasil analisis data,\n    - penanganan dari hasil analisis data,\n    - justifikasi teknik-teknik yang dipilih,\n    - perubahan yang dilakukan pada jawaban poin 1—5 jika ada,\n    - desain eksperimen,\n    - hasil eksperimen,\n    - analisis dari hasil eksperimen,\n    - kesimpulan,\n    - pembagian tugas/kerja per anggota kelompok\n\nBatas waktu pengumpulan:\n- _Deliverable_ poin 1: Senin, 25 April 2023, pukul 12.00 WIB\n- _Deliverable_ poin 2: Senin, 25 April 2023, pukul 21.00 WIB\n- _Deliverable_ poin 3: Senin, 25 April 2023, pukul 21.00 WIB","block_group":"f56a0e5588dd4fda8c865b5b702a0167"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"553ecdb37670428abcd0212eb8124951","deepnote_cell_type":"text-cell-h1"},"source":"# Praktikum IF3270 2023/2024","block_group":"e01f4768370c44ddae42fbcbef129e0f"},{"cell_type":"markdown","metadata":{"is_collapsed":false,"formattedRanges":[],"deepnote_app_block_visible":false,"cell_id":"7148cf360d72448c8ca6801bba2049c8","deepnote_cell_type":"text-cell-h1"},"source":"# BAGIAN 2","block_group":"d03bdc28be0e4cb7ab4ee69ee378205d"},{"cell_type":"markdown","metadata":{"is_collapsed":false,"formattedRanges":[{"type":"marks","marks":{"bold":true},"toCodePoint":16,"fromCodePoint":0}],"deepnote_app_block_visible":false,"cell_id":"c2344faf7ebe43548e585ee81095ad62","deepnote_cell_type":"text-cell-callout"},"source":"> Anggota Kelompok\r\nLaila Bilbina Khoiru Nisa - 13521016\r\nRaditya Naufal Abiyu - 13521022","block_group":"7ef3df464b1f47b0a69183c13fcc7ff5"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"76ff27bbb3a340dd95db59512c94d5ee","deepnote_cell_type":"text-cell-p"},"source":"\r","block_group":"35fe8a8afbfa4412ad04d4141d22c57b"},{"cell_type":"markdown","metadata":{"cell_id":"3b0e3843fcdf47a4ad6cbb94e5a79404","deepnote_cell_type":"markdown"},"source":"## 5. Desain Eksperimen dalam Konteks Machine Learning:\n\n### Tujuan Eksperimen\nTujuan dari eksperimen ini adalah untuk mengembangkan model machine learning yang dapat memprediksi risiko diabetes berdasarkan berbagai fitur kesehatan yang disediakan.\n\n### Variabel Independen (Fitur)\n\n- HighBP (Memiliki tekanan darah tinggi atau tidak)\n- HighChol (Memiliki kolesterol tinggi atau tidak)\n- BMI (Besaran Body Mass Index)\n- Smoker (Perokok atau bukan perokok)\n- HeartDiseaseorAttack (Memiliki riwayat penyakit antara jantung koroner dan serangan jantung atau tidak)\n- PhysActivity (Aktif secara fisik dalam 30 hari terakhir atau tidak)\n- Fruits (Mengonsumsi buah setiap hari atau tidak)\n- Veggies (Mengonsumsi sayur setiap hari atau tidak)\n- HvyAlcoholConsump (Peminum berat alkohol atau bukan)\n- AnyHealthcare (Memiliki perlindungan kesehatan atau tidak)\n- GenHtlth (Evaluasi mandiri terhadap kesehatan, skala 1-5)\n- MentHlth (Jumlah hari keadaan mental buruk dalam 30 hari terakhir)\n- PhysHlth (Jumlah hari keadaan fisik buruk dalam 30 hari terakhir)\n- DiffWalk (Memiliki kesulitan berjalan atau menaiki tangga)\n- Sex (Jenis kelamin: Male or Female)\n- Age (Usia dalam 13 kategori umur)\n- Education (Tingkat pendidikan, skala 1-6)\n- Income (Skala pendapatan)\n\n### Variabel Dependen\n- Diabetes (Apakah mengalami diabetes atau tidak)\n\n### Strategi Eksperimen\n\n- Data akan dibagi menjadi set train dan set validation.\n- Model machine learning, seperti logistic regression, decision tree, atau random forest, akan dilatih menggunakan set train.\n- Kinerja model akan dievaluasi menggunakan set validation dengan metrik evaluasi seperti akurasi, presisi, recall, atau F1-score.\n- Cross-validation mungkin digunakan untuk menghindari overfitting dan generalisir model.\n\n### Skema Validasi\n\n- Construction validity akan diperiksa dengan memastikan bahwa variabel independen yang dipilih mencerminkan faktor-faktor yang relevan untuk prediksi diabetes.\n- Internal validity akan dijaga dengan memastikan bahwa model tidak mengalami overfitting terhadap data train.\n- External validity akan diperiksa dengan memvalidasi kinerja model pada data validation yang tidak digunakan selama train.","block_group":"68e690f98d8046f593bb56efc1008647"},{"cell_type":"markdown","metadata":{"is_collapsed":false,"formattedRanges":[],"deepnote_app_block_visible":false,"cell_id":"ff5fa2c733e343dd920d8f8759a1ea1b","deepnote_cell_type":"text-cell-h2"},"source":"## 6. Implementasikan strategi eksperimen dan skema validasi yang telah ditentukan pada poin 5.\r","block_group":"5d54420b7ca94407b043be7eba7d5fe6"},{"cell_type":"code","metadata":{"source_hash":"1ca7a319","execution_start":1714050610568,"execution_millis":13515,"deepnote_to_be_reexecuted":false,"cell_id":"ae7616e515cb46b9b2d9fbf22965300a","deepnote_cell_type":"code"},"source":"! pip install imblearn\n! pip install scikit-optimize ","block_group":"3e3806241b6a40b5880ededd7d2d3d8a","execution_count":1,"outputs":[{"name":"stdout","text":"Collecting imblearn\n  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\nCollecting imbalanced-learn\n  Downloading imbalanced_learn-0.12.2-py3-none-any.whl (257 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.0/258.0 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scikit-learn>=1.0.2 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.1.2)\nRequirement already satisfied: scipy>=1.5.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.9.3)\nRequirement already satisfied: joblib>=1.1.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.2.0)\nRequirement already satisfied: numpy>=1.17.3 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.23.4)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (3.1.0)\nInstalling collected packages: imbalanced-learn, imblearn\nSuccessfully installed imbalanced-learn-0.12.2 imblearn-0.0\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nCollecting scikit-optimize\n  Downloading scikit_optimize-0.10.1-py2.py3-none-any.whl (107 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.7/107.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pyaml>=16.9\n  Downloading pyaml-24.4.0-py3-none-any.whl (24 kB)\nRequirement already satisfied: scipy>=1.1.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from scikit-optimize) (1.9.3)\nRequirement already satisfied: packaging>=21.3 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from scikit-optimize) (21.3)\nRequirement already satisfied: scikit-learn>=1.0.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from scikit-optimize) (1.1.2)\nRequirement already satisfied: numpy>=1.20.3 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from scikit-optimize) (1.23.4)\nRequirement already satisfied: joblib>=0.11 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from scikit-optimize) (1.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from packaging>=21.3->scikit-optimize) (3.0.9)\nCollecting PyYAML\n  Downloading PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m738.9/738.9 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.1.0)\nInstalling collected packages: PyYAML, pyaml, scikit-optimize\nSuccessfully installed PyYAML-6.0.1 pyaml-24.4.0 scikit-optimize-0.10.1\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/c0eb0927-8395-4e2c-a250-207caca3759e","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"8dd5705a","execution_start":1714050624085,"execution_millis":4241,"deepnote_to_be_reexecuted":false,"cell_id":"f0985728e0a64a16b51fed80b3fc2149","deepnote_cell_type":"code"},"source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import cross_val_score\nimport numpy as np\nfrom scipy import stats\n\n# Memuat dataset\ndf = pd.read_csv(\"diabetes.csv\")\n\n# encoding categorical menjadi numerical\ndf['Sex'] = df['Sex'].map({'F': 0.0, 'M': 1.0})\ndf['Diabetes'] = df['Diabetes'].astype(int)\n\n# Membersihkan data\n# Menghapus missing value\ndf.dropna(inplace=True)\n\n# Menghapus duplicate rows\ndf.drop_duplicates(inplace=True)\n\n# Menyeimbangkan data dengan oversampling SMOTE\nX = df.drop(columns=['Diabetes'])\ny = df['Diabetes']\nsmote = SMOTE()\nX_resampled, y_resampled = smote.fit_resample(X, y)\n\n# Membagi data menjadi set train dan set validation\nX_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)","block_group":"d90f3c0fffdf484daeb34edf3f29b43e","execution_count":2,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"ebec9b3b","execution_start":1714050628332,"execution_millis":32400,"deepnote_to_be_reexecuted":false,"cell_id":"55aca28d297d4b7bbd5eef1de094b80a","deepnote_cell_type":"code"},"source":"from sklearn.ensemble import RandomForestClassifier\n\n\nmodelF = RandomForestClassifier(bootstrap = True, criterion =  'gini', max_depth = 30, max_features = 'sqrt', min_samples_leaf= 4, min_samples_split= 2, n_estimators= 200)\nmodelF.fit(X_train, y_train)\ny_pred = modelF.predict(X_val)\nacc = accuracy_score(y_val, y_pred)\nprint(f\"Accuracy: {acc}\")\nprint(confusion_matrix(y_val, y_pred))\nf1 = f1_score(y_val, y_pred)\nprint(\"F1 score: \", f1)\ncv_score= cross_val_score(modelF, X_val, y_val, cv=5)\nprint(\"Mean CV score: \",cv_score.mean())","block_group":"dda8324aaa06466c8087a0154e0e5889","execution_count":3,"outputs":[{"name":"stdout","text":"Accuracy: 0.9118577670634322\n[[6318  284]\n [ 886 5786]]\nF1 score:  0.9081776801130121\nMean CV score:  0.8912154769051298\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/e17cf03c-83ff-4d36-bd58-64f2127ce409","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"2f5177e7","execution_start":1714050709803,"execution_millis":20495,"deepnote_to_be_reexecuted":false,"cell_id":"812302459382435a9de36066e6468017","deepnote_cell_type":"code"},"source":"y_pred = modelF.predict(X_test)\nacc = accuracy_score(y_test, y_pred)\nprint(f\"Accuracy: {acc}\")\nprint(confusion_matrix(y_test, y_pred))\nf1 = f1_score(y_test, y_pred)\nprint(\"F1 score: \", f1)\ncv_score= cross_val_score(modelF, X_test, y_test, cv=5)\nprint(\"Mean CV score: \",cv_score.mean())","block_group":"6b6f8203f27c41259b639f77dd14e071","execution_count":5,"outputs":[{"name":"stdout","text":"Accuracy: 0.9138190803350811\n[[7892  370]\n [1060 7271]]\nF1 score:  0.9104683195592287\nMean CV score:  0.897908692731367\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/d18ae2d2-631f-4571-bb0f-2e370a795a23","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"a2257c35","execution_start":1714050730306,"execution_millis":30315,"deepnote_to_be_reexecuted":false,"cell_id":"76a842f258854c00961f5f7b6ee2bcd1","deepnote_cell_type":"code"},"source":"from sklearn.ensemble import GradientBoostingClassifier\n\nmodelG = GradientBoostingClassifier()\n\nmodelG.fit(X_train, y_train)\ny_pred = modelG.predict(X_val)\nacc = accuracy_score(y_val, y_pred)\nprint(f\"Accuracy: {acc}\")\nprint(confusion_matrix(y_val, y_pred))\nf1 = f1_score(y_val, y_pred)\nprint(\"F1 score: \", f1)\ncv_score= cross_val_score(modelG, X_val, y_val, cv=5)\nprint(\"Mean CV score: \",cv_score.mean())","block_group":"40632416eed54a33992dfa501a8ca777","execution_count":6,"outputs":[{"name":"stdout","text":"Accuracy: 0.9019888503842097\n[[6172  430]\n [ 871 5801]]\nF1 score:  0.8991707354878711\nMean CV score:  0.901009455932629\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/9f0d36e0-0f4b-4f6f-a2d3-47a91d2f7d3c","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"e27f1cd2","execution_start":1714050783895,"execution_millis":16842,"deepnote_to_be_reexecuted":false,"cell_id":"9874370391464f0398c5f7324c7b7336","deepnote_cell_type":"code"},"source":"y_pred = modelG.predict(X_test)\nacc = accuracy_score(y_test, y_pred)\nprint(f\"Accuracy: {acc}\")\nprint(confusion_matrix(y_test, y_pred))\nf1 = f1_score(y_test, y_pred)\nprint(\"F1 score: \", f1)\ncv_score= cross_val_score(modelG, X_test, y_test, cv=5)\nprint(\"Mean CV score: \",cv_score.mean())","block_group":"33ff96d27ed44223bd33066e3d9a01f4","execution_count":8,"outputs":[{"name":"stdout","text":"Accuracy: 0.9055625866329174\n[[7706  556]\n [1011 7320]]\nF1 score:  0.9033133831060652\nMean CV score:  0.9035735398197783\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/70eeec9b-ac1c-4cca-b6ad-b32cb11f9ba0","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"acafe01","execution_start":1714050800740,"execution_millis":339723,"deepnote_to_be_reexecuted":false,"cell_id":"1d92e6296be1469c9d2100c6882e7036","deepnote_cell_type":"code"},"source":"from sklearn.ensemble import StackingClassifier\n\nestimators = [\n    ('rf', modelF),\n    ('gbc', modelG)\n]\n\nmodelS = StackingClassifier(estimators=estimators, final_estimator=RandomForestClassifier(bootstrap = True, criterion =  'gini', max_depth = 30, max_features = 'sqrt', min_samples_leaf= 4, min_samples_split= 2, n_estimators= 200))\nmodelS.fit(X_train, y_train)\ny_pred = modelS.predict(X_val)\nacc = accuracy_score(y_val, y_pred)\nprint(f\"Accuracy: {acc}\")\nprint(confusion_matrix(y_val, y_pred))\nf1 = f1_score(y_val, y_pred)\nprint(\"F1 score: \", f1)\ncv_score= cross_val_score(modelS, X_val, y_val, cv=5)\nprint(\"Mean CV score: \",cv_score.mean())","block_group":"2643619b37fe4ac2ac8a504109401827","execution_count":9,"outputs":[{"name":"stdout","text":"Accuracy: 0.9071869820702124\n[[6274  328]\n [ 904 5768]]\nF1 score:  0.9035087719298246\nMean CV score:  0.8974684553890867\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/03c3bff0-17ef-4a8e-bfcd-546b5d699f52","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"304f8059","execution_start":1714051140465,"execution_millis":1601,"deepnote_to_be_reexecuted":false,"cell_id":"9be783c2f62540a3bbc978fd1b36f4ae","deepnote_cell_type":"code"},"source":"y_pred = modelS.predict(X_test)\nacc = accuracy_score(y_test, y_pred)\nprint(f\"Accuracy: {acc}\")\nprint(confusion_matrix(y_test, y_pred))\nf1 = f1_score(y_test, y_pred)\nprint(\"F1 score: \", f1)","block_group":"dd16649df39c4f22bc9c051f34365c65","execution_count":10,"outputs":[{"name":"stdout","text":"Accuracy: 0.9103236304465738\n[[7827  435]\n [1053 7278]]\nF1 score:  0.9072550486163052\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/6b8bd552-9e80-4e82-a175-faa6cdc0af60","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"c48477d3","execution_start":1714051142082,"execution_millis":330306,"deepnote_to_be_reexecuted":false,"cell_id":"ccd920fe62a14f838253fcfbad554826","deepnote_cell_type":"code"},"source":"estimators = [\n    ('rf', modelF),\n    ('gbc', modelG)\n]\n\nmodelSS = StackingClassifier(estimators=estimators, final_estimator=GradientBoostingClassifier())\nmodelSS.fit(X_train, y_train)\ny_pred = modelSS.predict(X_val)\nacc = accuracy_score(y_val, y_pred)\nprint(f\"Accuracy: {acc}\")\nprint(confusion_matrix(y_val, y_pred))\nf1 = f1_score(y_val, y_pred)\nprint(\"F1 score: \", f1)\ncv_score= cross_val_score(modelSS, X_val, y_val, cv=5)\nprint(\"Mean CV score: \",cv_score.mean())","block_group":"26c4913c82e948528ab6be20a29cc41f","execution_count":11,"outputs":[{"name":"stdout","text":"Accuracy: 0.9136658128672593\n[[6397  205]\n [ 941 5731]]\nF1 score:  0.9091053299492386\nMean CV score:  0.901235104032289\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/64fde09e-93d3-43f2-a3a8-a155f60e9412","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"b78ea8b7","execution_start":1714051472391,"execution_millis":1024,"deepnote_to_be_reexecuted":false,"cell_id":"0e300b6a529b43a0bc5cc6c646110d3a","deepnote_cell_type":"code"},"source":"y_pred = modelSS.predict(X_test)\nacc = accuracy_score(y_test, y_pred)\nprint(f\"Accuracy: {acc}\")\nprint(confusion_matrix(y_test, y_pred))\nf1 = f1_score(y_test, y_pred)\nprint(\"F1 score: \", f1)","block_group":"0c3cff4513e348d1abfdc4342d3761df","execution_count":12,"outputs":[{"name":"stdout","text":"Accuracy: 0.9158078707888869\n[[7970  292]\n [1105 7226]]\nF1 score:  0.911855637579658\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/967f8348-b936-4d13-92a2-143a2633c835","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"668c7139","execution_start":1714049177890,"execution_millis":280,"deepnote_to_be_reexecuted":true,"cell_id":"f70b160a8a4641c99f6c3d3c626ba772","deepnote_cell_type":"code"},"source":"# Hypertuning param untuk Random Forest Classifier\n# from sklearn.model_selection import GridSearchCV\n\n# param_grid = {\n#     'n_estimators': [50, 100, 200],\n#     'max_depth': [None, 10, 20, 30],\n#     'min_samples_split': [2, 5, 10],\n#     'min_samples_leaf': [1, 2, 4],\n#     'max_features': ['sqrt', 'log2', None],\n#     'bootstrap': [True, False],\n#     'criterion': ['gini', 'entropy']\n# }\n\n# model = RandomForestClassifier()\n# grid_search = GridSearchCV(model, param_grid, cv=5)\n# grid_search.fit(X_train, y_train)\n# print(f\"Best parameter for random forest: {grid_search.best_params_}\")","block_group":"56d2ea8f8793439f9ff2b9909c1be431","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"is_collapsed":false,"formattedRanges":[],"deepnote_app_block_visible":false,"cell_id":"268f60e62a1945daaf207ca95d150a5d","deepnote_cell_type":"text-cell-h2"},"source":"## 7. Berdasarkan hasil prediksi yang dihasilkan, buatlah kesimpulan analisis hasil diabetes.\r","block_group":"aead5b09acce4286bc5a58725f71c120"},{"cell_type":"markdown","metadata":{"cell_id":"8b4a18b2cf934468a1719c3c33d8d821","deepnote_cell_type":"markdown"},"source":"Dari hasil prediksi yang diberikan oleh beberapa model ada 4 model yang memiliki performa terbaik yaitu Random Forest Classifier dengan parameter tuning, Gradient Boosting Classifier dan 2 model hasil stacking 2 model tersebut dengan final estimator yang berbeda. Dari hal tersebut dapat ditarik beberapa kesimpulan:\n\n## Performa Model:\n- Random Forest Classifier memiliki akurasi sebesar 91.26%. Ini menunjukkan bahwa model mampu dengan baik dalam mengklasifikasikan kedua kelas.\n- Gradient Boosting Classifier memiliki akurasi sebesar 90.29%. Meskipun sedikit lebih rendah dari Random Forest, akurasi ini tetap menunjukkan kinerja yang baik dari model.\n- Model gabungan Memiliki akurasi yang kurang lebih sama mendekati 91% dari kedua model dengan final estimator yang berbeda.\n## Confusion Matrix:\n- Random Forest Classifier memiliki +-300 prediksi salah untuk kelas negatif dan +-1000 prediksi salah untuk kelas positif.\n- Gradient Boosting Classifier memiliki +-500 prediksi salah untuk kelas negatif dan +-1000 prediksi salah untuk kelas positif.\n- Kedua model gabungan memiliki +-300 prediksi salah untuk kelas negatif dan +-1000 prediksi salah untuk kelas positif.\n- Keempatnya menunjukkan kecenderungan untuk melakukan lebih baik dalam mengklasifikasikan kelas positif dibandingkan kelas negatif, tetapi perbedaannya tidak signifikan.\n## Cross Validation Score:\nCross validation score mengukur seberapa baik model berkinerja pada data yang belum terlihat. Mean CV score dari semua model mendekati 90% atau bahkan melebihi 90% untuk beberapa model. Ini menunjukkan bahwa semua model memiliki kinerja yang stabil dan konsisten pada data yang tidak terlihat.\n## F1 Score:\nF1 score adalah metrik evaluasi yang mengukur kinerja model klasifikasi dengan memperhitungkan keseimbangan antara precision dan recall. Dalam kasus ini, semua model memiliki F1 score yang mendekati atau melebihi 90%, menunjukkan bahwa model-model tersebut memiliki kemampuan yang baik dalam mengklasifikasikan kedua kelas dengan baik.\n## Perbandingan Model:\nMeskipun Gradient Boosting Classifier memiliki akurasi yang sedikit lebih rendah daripada Random Forest Classifier, namun perbedaannya tidak signifikan. Secara umum, kedua model memiliki kinerja yang baik dalam mengklasifikasikan data diabetes. Secara teori hasil lebih baik bisa didapatkan apabila melakukan hyper parameter tuning untuk model Gradient Boosting Classifier. Parameter tuning untuk Gradient Boosting Classifier secara teori juga akan meningkatkan akurasi dan performa untuk kedua model gabungan","block_group":"38008b1e641344228ba63adc8ec15e8d"},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=314804e3-a157-4407-beaa-fcd6e7c41784' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_persisted_session":{"createdAt":"2024-04-25T13:01:47.673Z"},"deepnote_notebook_id":"dc2b368dfe2a4aa88d86ba86b88d82f5","deepnote_execution_queue":[]}}